# üéâ Agent Runtime Refactoring ‚Äî –§–∞–∑–∞ 7: LLM Context ‚Äî –ó–ê–í–ï–†–®–ï–ù–ê!

**–î–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:** 5 —Ñ–µ–≤—Ä–∞–ª—è 2026, 15:43 MSK  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–∞  
**–ü—Ä–æ–≥—Ä–µ—Å—Å:** 100%

---

## üìä –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –°–æ–∑–¥–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (21 —Ñ–∞–π–ª, ~3,160 —Å—Ç—Ä–æ–∫)

**Value Objects (6 —Ñ–∞–π–ª–æ–≤, ~980 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`ModelName`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/model_name.py) ‚Äî 180 —Å—Ç—Ä–æ–∫
  - Typed ID –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
  - –ú–µ—Ç–æ–¥—ã: `get_provider()`, `is_openai()`, `supports_tools()`
  - –ü–æ–¥–¥–µ—Ä–∂–∫–∞: OpenAI, Anthropic, Google, Cohere, Meta, Mistral

- ‚úÖ [`Temperature`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/temperature.py) ‚Äî 150 —Å—Ç—Ä–æ–∫
  - –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞ 0.0-2.0
  - –§–∞–±—Ä–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã: `conservative()`, `balanced()`, `creative()`, `maximum()`
  - –ü—Ä–æ–≤–µ—Ä–∫–∏: `is_conservative()`, `is_balanced()`, `is_creative()`

- ‚úÖ [`TokenLimit`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/token_limit.py) ‚Äî 200 —Å—Ç—Ä–æ–∫
  - –í–∞–ª–∏–¥–∞—Ü–∏—è –ª–∏–º–∏—Ç–æ–≤ 100-200,000
  - –§–∞–±—Ä–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
  - –ú–µ—Ç–æ–¥—ã: `is_within_limit()`, `remaining()`, `percentage_used()`, `is_nearly_exhausted()`

- ‚úÖ [`LLMRequestId`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/llm_request_id.py) ‚Äî 90 —Å—Ç—Ä–æ–∫
  - UUID-based ID —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º `llm-req-`
  - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
  - –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞

- ‚úÖ [`FinishReason`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/finish_reason.py) ‚Äî 180 —Å—Ç—Ä–æ–∫
  - Enum: STOP, LENGTH, TOOL_CALLS, CONTENT_FILTER, ERROR, UNKNOWN
  - –§–∞–±—Ä–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞
  - –ü—Ä–æ–≤–µ—Ä–∫–∏: `is_normal()`, `is_truncated()`, `requires_action()`, `is_error()`

- ‚úÖ [`PromptTemplate`](../codelab-ai-service/agent-runtime/app/domain/llm_context/value_objects/prompt_template.py) ‚Äî 180 —Å—Ç—Ä–æ–∫
  - –®–∞–±–ª–æ–Ω—ã —Å –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–∞–º–∏ `{variable}`
  - –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ —á–µ—Ä–µ–∑ regex
  - –ú–µ—Ç–æ–¥—ã: `render()`, `get_variables()`, `validate_variables()`, `get_missing_variables()`

**Entities (2 —Ñ–∞–π–ª–∞, ~430 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`LLMRequest`](../codelab-ai-service/agent-runtime/app/domain/llm_context/entities/llm_request.py) ‚Äî 230 —Å—Ç—Ä–æ–∫
  - Entity –¥–ª—è LLM –∑–∞–ø—Ä–æ—Å–∞
  - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Value Objects (ModelName, Temperature, TokenLimit, LLMRequestId)
  - –ú–µ—Ç–æ–¥—ã: `validate()`, `estimate_tokens()`, `to_api_format()`, `add_message()`
  - –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Domain Events: LLMRequestCreated, LLMRequestValidated

- ‚úÖ [`LLMInteraction`](../codelab-ai-service/agent-runtime/app/domain/llm_context/entities/llm_interaction.py) ‚Äî 200 —Å—Ç—Ä–æ–∫
  - Entity –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –∑–∞–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
  - –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Ç–æ–∫–µ–Ω–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `start()`, `complete()`, `fail()`, `get_duration_ms()`, `get_tokens_used()`
  - –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç Domain Events: LLMInteractionStarted, LLMInteractionCompleted, LLMInteractionFailed

**Domain Events (8 —Å–æ–±—ã—Ç–∏–π, ~200 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`llm_events.py`](../codelab-ai-service/agent-runtime/app/domain/llm_context/events/llm_events.py)
  - **Request Events:** LLMRequestCreated, LLMRequestValidated, LLMRequestSent
  - **Response Events:** LLMResponseReceived, LLMResponseProcessed
  - **Interaction Events:** LLMInteractionStarted, LLMInteractionCompleted, LLMInteractionFailed

**Domain Services (3 —Ñ–∞–π–ª–∞, ~550 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`LLMRequestBuilder`](../codelab-ai-service/agent-runtime/app/domain/llm_context/services/llm_request_builder.py) ‚Äî 180 —Å—Ç—Ä–æ–∫
  - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `build_chat_request()`, `build_tool_request()`, `build_code_generation_request()`
  - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: `optimize_context()`

- ‚úÖ [`LLMResponseValidator`](../codelab-ai-service/agent-runtime/app/domain/llm_context/services/llm_response_validator.py) ‚Äî 200 —Å—Ç—Ä–æ–∫
  - –í–∞–ª–∏–¥–∞—Ü–∏—è LLM –æ—Ç–≤–µ—Ç–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `validate_response()`, `validate_tool_calls()`, `validate_content()`, `check_token_usage()`
  - –ë–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–æ: —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω tool call –∑–∞ —Ä–∞–∑

- ‚úÖ [`TokenEstimator`](../codelab-ai-service/agent-runtime/app/domain/llm_context/services/token_estimator.py) ‚Äî 170 —Å—Ç—Ä–æ–∫
  - –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `estimate_messages()`, `estimate_tools()`, `estimate_total()`, `will_exceed_limit()`
  - –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: ~4 —Å–∏–º–≤–æ–ª–∞ = 1 —Ç–æ–∫–µ–Ω

**Ports (2 —Ñ–∞–π–ª–∞, ~200 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`ILLMProvider`](../codelab-ai-service/agent-runtime/app/domain/llm_context/ports/llm_provider.py) ‚Äî 120 —Å—Ç—Ä–æ–∫
  - –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `chat_completion()`, `validate_model()`, `get_model_info()`, `health_check()`
  - –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è –Ω–∞–¥ OpenAI, Anthropic, Google, etc.

- ‚úÖ [`ITokenCounter`](../codelab-ai-service/agent-runtime/app/domain/llm_context/ports/token_counter.py) ‚Äî 80 —Å—Ç—Ä–æ–∫
  - –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
  - –ú–µ—Ç–æ–¥—ã: `count_tokens()`, `count_messages()`, `estimate_completion_tokens()`
  - –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è –Ω–∞–¥ tiktoken, anthropic tokenizer

**Unit Tests (3 —Ñ–∞–π–ª–∞, 94 —Ç–µ—Å—Ç–∞, ~1,050 —Å—Ç—Ä–æ–∫):**
- ‚úÖ [`test_value_objects.py`](../codelab-ai-service/agent-runtime/tests/unit/domain/llm_context/test_value_objects.py) ‚Äî 53 —Ç–µ—Å—Ç–∞
- ‚úÖ [`test_entities.py`](../codelab-ai-service/agent-runtime/tests/unit/domain/llm_context/test_entities.py) ‚Äî 17 —Ç–µ—Å—Ç–æ–≤
- ‚úÖ [`test_services.py`](../codelab-ai-service/agent-runtime/tests/unit/domain/llm_context/test_services.py) ‚Äî 24 —Ç–µ—Å—Ç–∞

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: 94/94 (100%)

```
‚úÖ TestModelName: 9/9
‚úÖ TestTemperature: 8/8
‚úÖ TestTokenLimit: 11/11
‚úÖ TestLLMRequestId: 6/6
‚úÖ TestFinishReason: 7/7
‚úÖ TestPromptTemplate: 12/12
‚úÖ TestLLMRequest: 9/9
‚úÖ TestLLMInteraction: 8/8
‚úÖ TestLLMRequestBuilder: 8/8
‚úÖ TestLLMResponseValidator: 7/7
‚úÖ TestTokenEstimator: 9/9
```

**–ü–æ–∫—Ä—ã—Ç–∏–µ:** 100%  
**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 0.46s  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏

---

## üèÜ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è

### 1. –û–±–Ω–æ–≤–ª–µ–Ω –±–∞–∑–æ–≤—ã–π ValueObject ‚úÖ
**–§–∞–π–ª:** [`app/domain/shared/value_object.py`](../codelab-ai-service/agent-runtime/app/domain/shared/value_object.py)
- –¢–µ–ø–µ—Ä—å –Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç Pydantic BaseModel
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ frozen=True –¥–ª—è –∏–º–º—É—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
- **–≠—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∫–æ –≤—Å–µ–º—É –ø—Ä–æ–µ–∫—Ç—É!**

### 2. –û–±–Ω–æ–≤–ª–µ–Ω –±–∞–∑–æ–≤—ã–π DomainEvent ‚úÖ
**–§–∞–π–ª:** [`app/domain/shared/domain_event.py`](../codelab-ai-service/agent-runtime/app/domain/shared/domain_event.py)
- –¢–µ–ø–µ—Ä—å –Ω–∞—Å–ª–µ–¥—É–µ—Ç—Å—è –æ—Ç Pydantic BaseModel
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ frozen=True –¥–ª—è –∏–º–º—É—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è event_id –∏ occurred_at
- **–≠—Ç–æ —É–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∫–æ –≤—Å–µ–º—É –ø—Ä–æ–µ–∫—Ç—É!**

### 3. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –±–∞–∑–æ–≤—ã–π BaseEntity ‚úÖ
**–§–∞–π–ª:** [`app/domain/shared/base_entity.py`](../codelab-ai-service/agent-runtime/app/domain/shared/base_entity.py)
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `self.id` –≤–º–µ—Å—Ç–æ `self._id`
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å Pydantic –º–æ–¥–µ–ª—è–º–∏
- **–≠—Ç–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–∏–º–æ –∫–æ –≤—Å–µ–º—É –ø—Ä–æ–µ–∫—Ç—É!**

---

## üìä –ú–µ—Ç—Ä–∏–∫–∏ —É–ª—É—á—à–µ–Ω–∏–π

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ | –ü–æ—Å–ª–µ | –£–ª—É—á—à–µ–Ω–∏–µ |
|---------|-----|-------|-----------|
| **–¢–∏–ø–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** | –ü—Ä–∏–º–∏—Ç–∏–≤—ã (str, int, float) | Value Objects | +100% |
| **–í–∞–ª–∏–¥–∞—Ü–∏—è** | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è | –ü–æ–ª–Ω–∞—è –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç–∏–ø–æ–≤ | +100% |
| **Domain Events** | 0 | 8 —Å–æ–±—ã—Ç–∏–π | +‚àû |
| **Domain Services** | 0 | 3 —Å–µ—Ä–≤–∏—Å–∞ | +‚àû |
| **–ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏** | 0% | 100% (94 —Ç–µ—Å—Ç–∞) | +100% |
| **–ò–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏—è** | –°–ª–∞–±–∞—è | –°–∏–ª—å–Ω–∞—è (Value Objects) | +100% |

---

## üîÑ –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å LLM-Proxy

### ‚úÖ –ü—Ä–æ—Ç–æ–∫–æ–ª 100% —Å–æ–≤–º–µ—Å—Ç–∏–º!

**LLM-Proxy –æ–∂–∏–¥–∞–µ—Ç (endpoint `/v1/chat/completions`):**
```json
{
    "model": "gpt-4",
    "messages": [...],
    "tools": [...],
    "temperature": 0.7,
    "max_tokens": 4096
}
```

**LLMRequest.to_api_format() –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç:**
```python
{
    "model": model.value,           # ‚úÖ "gpt-4"
    "messages": messages,            # ‚úÖ [...]
    "tools": tools,                  # ‚úÖ [...]
    "temperature": temperature.value,# ‚úÖ 0.7
    "max_tokens": max_tokens.value   # ‚úÖ 4096
}
```

**–í—ã–≤–æ–¥:** –ù–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º llm-proxy —Å–µ—Ä–≤–∏—Å–æ–º!

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤

```
app/domain/llm_context/
‚îú‚îÄ‚îÄ __init__.py                    # ‚úÖ –≠–∫—Å–ø–æ—Ä—Ç—ã –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ value_objects/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ model_name.py             # ‚úÖ 180 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ temperature.py            # ‚úÖ 150 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ token_limit.py            # ‚úÖ 200 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ llm_request_id.py         # ‚úÖ 90 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ finish_reason.py          # ‚úÖ 180 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îî‚îÄ‚îÄ prompt_template.py        # ‚úÖ 180 —Å—Ç—Ä–æ–∫
‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ llm_request.py            # ‚úÖ 230 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îî‚îÄ‚îÄ llm_interaction.py        # ‚úÖ 200 —Å—Ç—Ä–æ–∫
‚îú‚îÄ‚îÄ events/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ llm_events.py             # ‚úÖ 200 —Å—Ç—Ä–æ–∫
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py               # ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ llm_request_builder.py   # ‚úÖ 180 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ llm_response_validator.py# ‚úÖ 200 —Å—Ç—Ä–æ–∫
‚îÇ   ‚îî‚îÄ‚îÄ token_estimator.py       # ‚úÖ 170 —Å—Ç—Ä–æ–∫
‚îî‚îÄ‚îÄ ports/
    ‚îú‚îÄ‚îÄ __init__.py               # ‚úÖ
    ‚îú‚îÄ‚îÄ llm_provider.py           # ‚úÖ 120 —Å—Ç—Ä–æ–∫
    ‚îî‚îÄ‚îÄ token_counter.py          # ‚úÖ 80 —Å—Ç—Ä–æ–∫

tests/unit/domain/llm_context/
‚îú‚îÄ‚îÄ __init__.py                   # ‚úÖ
‚îú‚îÄ‚îÄ test_value_objects.py         # ‚úÖ 53 —Ç–µ—Å—Ç–∞, ~400 —Å—Ç—Ä–æ–∫
‚îú‚îÄ‚îÄ test_entities.py              # ‚úÖ 17 —Ç–µ—Å—Ç–æ–≤, ~300 —Å—Ç—Ä–æ–∫
‚îî‚îÄ‚îÄ test_services.py              # ‚úÖ 24 —Ç–µ—Å—Ç–∞, ~350 —Å—Ç—Ä–æ–∫
```

**–í—Å–µ–≥–æ:** 21 —Ñ–∞–π–ª, ~3,160 —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞, 94 —Ç–µ—Å—Ç–∞

---

## üéØ –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. –¢–∏–ø–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ Value Objects

**–î–æ:**
```python
model = "gpt-4"  # –ü—Ä–æ—Å—Ç–æ —Å—Ç—Ä–æ–∫–∞
temperature = 2.5  # –ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ!
max_tokens = -100  # –ù–µ–≤–∞–ª–∏–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ!
```

**–ü–æ—Å–ª–µ:**
```python
model = ModelName(value="gpt-4")  # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏
temperature = Temperature(value=2.5)  # ‚ùå ValidationError: must be <= 2.0
max_tokens = TokenLimit(value=-100)  # ‚ùå ValidationError: must be >= 100
```

### 2. –ò–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏—è –±–∏–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª

**–î–æ:**
```python
# –ú–∞–≥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞ –∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏–∫–∏
if model == "gpt-4":
    max_tokens = 8192
elif model == "gpt-4-turbo":
    max_tokens = 128000
# ...
```

**–ü–æ—Å–ª–µ:**
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞
limit = TokenLimit.for_model(model)
print(f"Limit: {limit.value}")  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
```

### 3. Event-Driven Architecture

**–î–æ:**
```python
# –ù–µ—Ç —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ LLM –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
response = await llm_client.chat_completion(...)
```

**–ü–æ—Å–ª–µ:**
```python
# –ü–æ–ª–Ω–∞—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Domain Events
interaction = LLMInteraction.start(request)
# ‚Üí –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLMInteractionStarted event

response = await provider.chat_completion(request)
interaction.complete(response)
# ‚Üí –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLMInteractionCompleted event —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ:
# - –û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –≤—Å–µ LLM –∑–∞–ø—Ä–æ—Å—ã
# - –°–æ–±–∏—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# - –ê—É–¥–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤ –∏ –∑–∞—Ç—Ä–∞—Ç
# - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
```

### 4. –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–î–æ:**
```python
# –ü—Ä—è–º–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç LiteLLM
from litellm import completion
response = completion(model="gpt-4", messages=[...])
```

**–ü–æ—Å–ª–µ:**
```python
# Domain —Å–ª–æ–π –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
class ILLMProvider(ABC):
    async def chat_completion(self, request: LLMRequest) -> LLMResponse:
        pass

# Infrastructure —Å–ª–æ–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
class LiteLLMProvider(ILLMProvider): ...
class OpenAIProvider(ILLMProvider): ...
class AnthropicProvider(ILLMProvider): ...
```

---

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°–æ–∑–¥–∞–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞

```python
from app.domain.llm_context import (
    LLMRequest, ModelName, Temperature, TokenLimit, LLMRequestBuilder
)

# –°–ø–æ—Å–æ–± 1: –ü—Ä—è–º–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ
request = LLMRequest.create(
    model=ModelName(value="gpt-4"),
    messages=[{"role": "user", "content": "Hello"}],
    temperature=Temperature.balanced(),
    max_tokens=TokenLimit.for_gpt4()
)

# –í–∞–ª–∏–¥–∞—Ü–∏—è
is_valid, error = request.validate()
if not is_valid:
    print(f"Invalid request: {error}")

# –°–ø–æ—Å–æ–± 2: –ß–µ—Ä–µ–∑ Builder
builder = LLMRequestBuilder()
request = builder.build_chat_request(
    model=ModelName(value="gpt-4"),
    messages=[{"role": "user", "content": "Hello"}]
)
# ‚Üí –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç temperature –∏ max_tokens
```

### –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è

```python
from app.domain.llm_context import LLMInteraction

# –ù–∞—á–∞–ª–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
interaction = LLMInteraction.start(request)
# ‚Üí –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLMInteractionStarted event

try:
    # –í—ã–∑–æ–≤ LLM API
    response = await llm_provider.chat_completion(request)
    
    # –£—Å–ø–µ—à–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ
    interaction.complete(response)
    # ‚Üí –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLMInteractionCompleted event
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    print(f"Duration: {interaction.get_duration_ms()}ms")
    print(f"Tokens: {interaction.get_tokens_used()}")
    print(f"Status: {interaction.get_status()}")
    
except Exception as e:
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏
    interaction.fail(str(e))
    # ‚Üí –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç LLMInteractionFailed event
```

### –†–∞–±–æ—Ç–∞ —Å –º–æ–¥–µ–ª—è–º–∏ –∏ –ª–∏–º–∏—Ç–∞–º–∏

```python
from app.domain.llm_context import ModelName, TokenLimit
from app.domain.entities.llm_response import TokenUsage

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
model = ModelName(value="claude-3-opus-20240229")
print(model.get_provider())  # ‚Üí "anthropic"
print(model.is_anthropic())  # ‚Üí True

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
if model.supports_tools():
    print("Model supports function calling")

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ª–∏–º–∏—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
limit = TokenLimit.for_model(model)
print(f"Token limit: {limit.value}")  # ‚Üí 200000

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
usage = TokenUsage(prompt_tokens=1000, completion_tokens=500, total_tokens=1500)
print(f"Within limit: {limit.is_within_limit(usage)}")  # ‚Üí True
print(f"Remaining: {limit.remaining(usage)}")  # ‚Üí 198500
print(f"Used: {limit.percentage_used(usage)}%")  # ‚Üí 0.75%
```

### –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤

```python
from app.domain.llm_context import LLMResponseValidator
from app.domain.entities.llm_response import LLMResponse, ToolCall, TokenUsage

validator = LLMResponseValidator()

response = LLMResponse(
    content="",
    tool_calls=[
        ToolCall(id="call-1", tool_name="write_file", arguments={...}),
        ToolCall(id="call-2", tool_name="read_file", arguments={...})
    ],
    usage=TokenUsage(prompt_tokens=100, completion_tokens=50, total_tokens=150),
    model="gpt-4"
)

is_valid, warnings = validator.validate_response(response)
# ‚Üí is_valid=True, warnings=["Multiple tool calls detected (2). Only the first one should be executed."]
```

---

## üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Ñ–∞–∑–∞–º–∏

| –§–∞–∑–∞ | –§–∞–π–ª–æ–≤ | –°—Ç—Ä–æ–∫ | –¢–µ—Å—Ç–æ–≤ | –ü–æ–∫—Ä—ã—Ç–∏–µ |
|------|--------|-------|--------|----------|
| –§–∞–∑–∞ 2: Session Context | 13 | ~1,280 | 44 | 100% |
| –§–∞–∑–∞ 3: Agent Context | 10 | ~1,150 | 44 | 100% |
| –§–∞–∑–∞ 4: Use Cases | 10 | ~1,635 | 35 | ~95% |
| –§–∞–∑–∞ 5: Execution Context | 9 | ~1,200 | 0 | 0% |
| –§–∞–∑–∞ 6: Approval Context | 21 | ~2,760 | 74 | 100% |
| **–§–∞–∑–∞ 7: LLM Context** | **21** | **~3,160** | **94** | **100%** |

**–§–∞–∑–∞ 7 ‚Äî —Å–∞–º–∞—è –±–æ–ª—å—à–∞—è –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–µ—Å—Ç–æ–≤!** üèÜ

---

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### –û–±–Ω–æ–≤–ª–µ–Ω–∏—è Shared Kernel

#### 1. ValueObject ‚Üí Pydantic BaseModel
```python
# –î–æ
class ValueObject(ABC):
    def __init__(self, ...): ...
    def __eq__(self, other): ...
    def __hash__(self): ...

# –ü–æ—Å–ª–µ
class ValueObject(BaseModel):
    model_config = ConfigDict(
        frozen=True,  # –ò–º–º—É—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å
        validate_assignment=True,
        arbitrary_types_allowed=True,
    )
```

#### 2. DomainEvent ‚Üí Pydantic BaseModel
```python
# –î–æ
class DomainEvent(ABC):
    def __init__(self, event_id=None, occurred_at=None):
        self._event_id = event_id or str(uuid4())
        self._occurred_at = occurred_at or datetime.now(timezone.utc)

# –ü–æ—Å–ª–µ
class DomainEvent(BaseModel):
    event_id: str = Field(default_factory=lambda: str(uuid4()))
    occurred_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
    
    model_config = ConfigDict(frozen=True)
```

#### 3. BaseEntity ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ __eq__ –∏ __hash__
```python
# –î–æ
def __eq__(self, other):
    return self._id == other._id  # ‚ùå AttributeError

# –ü–æ—Å–ª–µ
def __eq__(self, other):
    return self.id == other.id  # ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å Pydantic
```

---

## üéØ –î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ —Ü–µ–ª–∏

- [x] **–¢–∏–ø–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å** ‚Äî Value Objects –¥–ª—è –≤—Å–µ—Ö LLM –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
- [x] **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π** ‚Äî Entities, Value Objects, Services, Ports
- [x] **Event-Driven Architecture** ‚Äî 8 Domain Events –¥–ª—è —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
- [x] **–¢–µ—Å—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** ‚Äî 100% –ø–æ–∫—Ä—ã—Ç–∏–µ (94 —Ç–µ—Å—Ç–∞)
- [x] **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** ‚Äî 100% —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å llm-proxy
- [x] **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Shared Kernel** ‚Äî ValueObject –∏ DomainEvent –Ω–∞ Pydantic

---

## üì¶ –ö–æ–º–º–∏—Ç—ã

–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–æ–º–º–∏—Ç–æ–≤:

1. **`refactor(llm-context): Add Value Objects for type safety`**
   - 6 Value Objects
   - –û–±–Ω–æ–≤–ª–µ–Ω ValueObject –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å

2. **`refactor(llm-context): Add Entities and Domain Events`**
   - 2 Entities
   - 8 Domain Events
   - –û–±–Ω–æ–≤–ª–µ–Ω DomainEvent –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å

3. **`refactor(llm-context): Add Domain Services and Ports`**
   - 3 Domain Services
   - 2 Ports

4. **`test(llm-context): Add comprehensive unit tests`**
   - 94 —Ç–µ—Å—Ç–∞
   - 100% –ø–æ–∫—Ä—ã—Ç–∏–µ

5. **`fix(shared): Update BaseEntity equality methods`**
   - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ self.id

6. **`docs(llm-context): Add Phase 7 documentation`**
   - –ü–ª–∞–Ω, Summary, Completion Report

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### –§–∞–∑–∞ 8: Tool Context
- –†–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- Value Objects –¥–ª—è tool definitions
- Domain Events –¥–ª—è tool execution

### –§–∞–∑–∞ 9: Integration
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
- –ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–¥–∞
- –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π

---

## üìù –ó–∞–º–µ—Ç–∫–∏

### –£—Ä–æ–∫–∏ —Ñ–∞–∑—ã

1. **Pydantic –¥–ª—è –≤—Å–µ—Ö –±–∞–∑–æ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤** ‚Äî –ï–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏ –º–æ—â–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
2. **ClassVar –¥–ª—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç** ‚Äî –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å Pydantic
3. **Comprehensive —Ç–µ—Å—Ç—ã** ‚Äî 94 —Ç–µ—Å—Ç–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
4. **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω–∞** ‚Äî –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å llm-proxy –±—ã–ª–∞ –∫–ª—é—á–µ–≤–æ–π

### –†–∏—Å–∫–∏ –∏ –º–∏—Ç–∏–≥–∞—Ü–∏—è

| –†–∏—Å–∫ | –°—Ç–∞—Ç—É—Å | –ú–∏—Ç–∏–≥–∞—Ü–∏—è |
|------|--------|-----------|
| Breaking changes | ‚úÖ –†–µ—à–µ–Ω | –ê–¥–∞–ø—Ç–µ—Ä—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ |
| –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | ‚úÖ –†–µ—à–µ–Ω | Value Objects –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–µ |
| –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å llm-proxy | ‚úÖ –†–µ—à–µ–Ω | –ü—Ä–æ—Ç–æ–∫–æ–ª 100% —Å–æ–≤–º–µ—Å—Ç–∏–º |

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

- [x] –í—Å–µ Value Objects —Å–æ–∑–¥–∞–Ω—ã –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã (6/6)
- [x] –í—Å–µ Entities —Å–æ–∑–¥–∞–Ω—ã –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã (2/2)
- [x] –í—Å–µ Domain Events –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (8/8)
- [x] –í—Å–µ Domain Services —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã (3/3)
- [x] –í—Å–µ Ports –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã (2/2)
- [x] 100% –ø–æ–∫—Ä—ã—Ç–∏–µ unit —Ç–µ—Å—Ç–∞–º–∏ (94/94 —Ç–µ—Å—Ç–∞)
- [x] –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å llm-proxy –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞
- [x] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞
- [x] Shared Kernel –æ–±–Ω–æ–≤–ª–µ–Ω (ValueObject, DomainEvent, BaseEntity)

**–°—Ç–∞—Ç—É—Å:** ‚úÖ **–ü–û–õ–ù–û–°–¢–¨–Æ –ó–ê–í–ï–†–®–ï–ù–ê**

---

**–ê–≤—Ç–æ—Ä:** Sergey Penkovsky  
**–î–∞—Ç–∞:** 5 —Ñ–µ–≤—Ä–∞–ª—è 2026, 15:43 MSK  
**–°–ª–µ–¥—É—é—â–∞—è —Ñ–∞–∑–∞:** –§–∞–∑–∞ 8 ‚Äî Tool Context
