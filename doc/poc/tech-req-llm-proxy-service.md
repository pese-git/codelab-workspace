
# üü• **–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï

LLM Proxy Service (POC –≤–∞—Ä–∏–∞–Ω—Ç)**
–í–µ—Ä—Å–∏—è: 1.0
–°—Ç–∞—Ç—É—Å: POC / MVP

---

# 1. –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã

**LLM Proxy Service** ‚Äî —ç—Ç–æ —Å–µ—Ä–≤–∏—Å-–ø–æ—Å—Ä–µ–¥–Ω–∏–∫, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∏ –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ä–∞–∑–ª–∏—á–Ω—ã–º Large Language Models:

* OpenAI API —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ –º–æ–¥–µ–ª–∏ (GPT-4.1, GPT-4.1-mini, GPT-o)
* Azure OpenAI
* Anthropic (Claude 3.x)
* Local LLM (—á–µ—Ä–µ–∑ vLLM / Ollama / LM Studio Gateway)
* –ë—É–¥—É—â–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è: DeepSeek, Gemini, Mistral.

LLM Proxy –∞–±—Å—Ç—Ä–∞–≥–∏—Ä—É–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç uniform API –¥–ª—è:

* Agent Runtime Service
* Gateway Service
* –°–∏—Å—Ç–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
* –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

POC-–≤–∞—Ä–∏–∞–Ω—Ç –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:

* Streaming LLM responses
* Proxying –º–æ–¥–µ–ª—å–Ω—ã—Ö API
* –ï–¥–∏–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤
* Rate limiting (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)
* –õ–æ–≥–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞
* –ë–∞–∑–æ–≤—ã–µ retry-–ø–æ–ª–∏—Ç–∏–∫–∏
* –ê–±—Å—Ç—Ä–∞–∫—Ü–∏—é tool-calls –≤–Ω—É—Ç—Ä–∏ LLM –æ—Ç–≤–µ—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

---

# 2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

### POC –¥–æ–ª–∂–µ–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å:

### ‚úîÔ∏è 2.1 Uniform API –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

–ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞:

```
POST /llm/completions
POST /llm/chat
POST /llm/stream
```

### ‚úîÔ∏è 2.2 –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Streaming —Ç–æ–∫–µ–Ω–æ–≤

* Token-by-token
* –û–±—Ä–∞–±–æ—Ç–∫–∞ chunk-–∏, –≤–∫–ª—é—á–∞—è tool-calls
* –§–æ—Ä–º–∞—Ç JSON-lines (LLM chunk)

–ü—Ä–∏–º–µ—Ä:

```json
{"token": "import", "index": 1}
{"token": " ", "index": 2}
{"tool_call": {...}}
```

### ‚úîÔ∏è 2.3 Proxy –∫ –ª—é–±—ã–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º

POC –¥–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –º–∏–Ω–∏–º—É–º:

| Provider                | API             | Streaming | –°—Ç–∞—Ç—É—Å   |
| ----------------------- | --------------- | --------- | -------- |
| OpenAI                  | ChatCompletions | ‚úîÔ∏è        | Required |
| Anthropic               | Messages        | ‚úîÔ∏è        | Optional |
| Local LLM (Ollama/vLLM) | compatible      | ‚úîÔ∏è        | Optional |

### ‚úîÔ∏è 2.4 –õ–æ–≥–∏ –∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞

* –õ–æ–≥–∏ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—à–∏–±–æ–∫
* –ò—Å—Ç–æ—Ä–∏—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
* Execution trace ID (uuid per request)

### ‚úîÔ∏è 2.5 Rate limiting (MVP)

* per-user (API key)
* per-IP (fallback)
* per-model (soft limit)

### ‚úîÔ∏è 2.6 –§—ç–π–ª–æ–≤–µ—Ä –∏ retry

* retry –ø—Ä–∏ 500/timeout –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
* –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ)
* –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è

### ‚úîÔ∏è 2.7 –§–∏—á–∏, –ù–ï –≤—Ö–æ–¥—è—â–∏–µ –≤ POC

* –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ LLM –æ—Ç–≤–µ—Ç–æ–≤
* inference batching
* advanced routing (semantic routing)
* load-balancing –º–µ–∂–¥—É GPU —É–∑–ª–∞–º–∏

---

# 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```mermaid
flowchart LR
ARS[Agent Runtime Service] --> PROXY[LLM Proxy API]
GW[Gateway] --> PROXY

PROXY --> ROUTER[Model Router]
ROUTER --> PROVIDER1[OpenAI Provider]
ROUTER --> PROVIDER2[Anthropic Provider]
ROUTER --> PROVIDER3[Local LLM Adapter]

PROVIDER1 --> STREAMER[Streaming Normalizer]
PROVIDER2 --> STREAMER
PROVIDER3 --> STREAMER

STREAMER --> ARS
STREAMER --> GW
```

---

# 4. –ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞

### 4.1 API Layer

–ú–µ—Ç–æ–¥—ã:

* `/llm/chat`
* `/llm/stream`
* `/llm/models`

–ü—Ä–æ—Ç–æ–∫–æ–ª: REST + SSE (–∏–ª–∏ WS –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏).

### 4.2 Request Validator

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:

* –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å payload
* –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π –¥–æ—Å—Ç—É–ø–∞
* –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏

### 4.3 Model Router

–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–π:

* –∫–∞–∫–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
* –∫–∞–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞—Ç—å
* –∫–∞–∫–æ–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–ø–æ–ª–Ω–∏—Ç—å

Routing –º–æ–∂–µ—Ç –æ—Å–Ω–æ–≤—ã–≤–∞—Ç—å—Å—è –Ω–∞:

* model id (–Ω–∞–ø—Ä–∏–º–µ—Ä: "gpt-4.1")
* project settings (–≤ –±—É–¥—É—â–µ–º)
* –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞

### 4.4 Provider Adapters

–ú–∏–Ω–∏–º—É–º –≤ POC:

```
providers/
  openai_provider.py
  anthropic_provider.py
  local_llm_provider.py
```

–ö–∞–∂–¥—ã–π –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:

```python
class ProviderAdapter:
    def stream(self, request): ...
    def complete(self, request): ...
    def get_models(self): ...
```

### 4.5 Streaming Normalizer

–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è chunk-–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç:

```json
{
  "type": "token",
  "token": "...",
  "index": 124
}
```

–ü–æ–¥–¥–µ—Ä–∂–∫–∞:

* tokens
* tool_calls
* assistant messages
* reasoning artifacts (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)

### 4.6 Rate Limiter

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π per-IP + per-key –ª–∏–º–∏—Ç.

### 4.7 Logging & Trace

* Request ID
* Timestamps
* Provider latency
* Tokens/sec
* Alerts on timeout

---

# 5. API —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è

---

## 5.1 **POST /llm/stream**

### Request:

```json
{
  "model": "gpt-4.1-mini",
  "messages": [
    {"role": "user", "content": "Explain RAG"}
  ],
  "temperature": 0.5
}
```

### Response (SSE –∏–ª–∏ chunked JSON):

```
event: token
data: {"token": "Retrieval"}

event: token
data: {"token": " Augmented"}

event: token
data: {"token": " Generation"}

event: end
data: {"usage": {...}}
```

---

## 5.2 **POST /llm/chat**

–û–¥–Ω–æ–∫—Ä–∞—Ç–Ω—ã–π non-streaming –∑–∞–ø—Ä–æ—Å.

---

## 5.3 **GET /llm/models**

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:

```json
[
  {"id": "gpt-4.1-mini", "provider": "openai", "max_tokens": 128000},
  {"id": "claude-3-sonnet", "provider": "anthropic"},
  {"id": "local-7b", "provider": "local"}
]
```

---

# 6. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

Config-—Ñ–∞–π–ª POC:

```yaml
default_provider: openai

providers:
  openai:
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
  anthropic:
    base_url: https://api.anthropic.com/v1
    api_key: ${ANTHROPIC_API_KEY}
  local:
    base_url: http://localhost:8001/v1
```

---

# 7. –û—à–∏–±–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞

### –¢–∏–ø–æ–≤—ã–µ –æ—à–∏–±–∫–∏:

| –ö–æ–¥ | –û—à–∏–±–∫–∞          | –û–ø–∏—Å–∞–Ω–∏–µ             |
| --- | --------------- | -------------------- |
| 400 | INVALID_REQUEST | –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π payload |
| 401 | UNAUTHORIZED    | –Ω–µ—Ç —Ç–æ–∫–µ–Ω–∞           |
| 429 | RATE_LIMIT      | –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç       |
| 502 | PROVIDER_ERROR  | –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞    |
| 504 | TIMEOUT         | LLM –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª       |

–í —Å–ª—É—á–∞–µ provider error ‚Üí –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π retry: 1 —Ä–∞–∑.

---

# 8. –ù–µ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

### Performance

* —Å—Ç–∞—Ä—Ç —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ < 200–º—Å
* –∑–∞–¥–µ—Ä–∂–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ < 120–º—Å
* throughput: ~10 RPS (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è POC)

### Security

* API –∫–ª—é—á–∏ –Ω–µ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
* HTTPS –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (—á–µ—Ä–µ–∑ nginx/traefik)

### Scalability

* Stateless —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–º–æ–∂–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å)

---

# 9. –ü–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ POC

### –ù–µ–¥–µ–ª—è 1

* API –º–µ—Ç–æ–¥—ã `/llm/chat`, `/llm/stream`
* OpenAI provider adapter
* Streaming normalization

### –ù–µ–¥–µ–ª—è 2

* Rate limiting
* Logging & tracing
* Local LLM provider

### –ù–µ–¥–µ–ª—è 3

* Integration —Å Agent Runtime Service
* Load —Ç–µ—Å—Ç—ã
* –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

---

# 10. Acceptance Criteria

LLM Proxy Service —Å—á–∏—Ç–∞–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º, –µ—Å–ª–∏:

‚úî –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã –æ—Ç ARS –∏ Gateway
‚úî –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø—Ä–æ–∫—Å–∏—Ä—É–µ—Ç –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º
‚úî –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç streaming
‚úî –≤—ã–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç chunk-–∏
‚úî –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–∏–Ω–∏–º—É–º 2 –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
‚úî –ª–æ–≥–∏—Ä—É–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—à–∏–±–∫–∏
‚úî —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ–¥ –Ω–∞–≥—Ä—É–∑–∫–æ–π 10 RPS
